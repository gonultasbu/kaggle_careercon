{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# TODO Test Featuretools\n",
    "#Â TODO Test LSTM for Feature Extraction\n",
    "# Test both weighted and unweighted class approaches for better CV-LB estimation.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import rcParams\n",
    "%matplotlib inline\n",
    "le = preprocessing.LabelEncoder()\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import featuretools as ft \n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, GroupShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def plot_confusion_matrix(truth, pred, classes, normalize=False, title=''):\n",
    "    cm = confusion_matrix(truth, pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion matrix', size=15)\n",
    "    plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_distribution(df1, df2, label1, label2, features,a=2,b=5):\n",
    "    i = 0\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(a,b,figsize=(17,9))\n",
    "\n",
    "    for feature in features:\n",
    "        i += 1\n",
    "        plt.subplot(a,b,i)\n",
    "        sns.kdeplot(df1[feature], bw=0.5,label=label1)\n",
    "        sns.kdeplot(df2[feature], bw=0.5,label=label2)\n",
    "        plt.xlabel(feature, fontsize=9)\n",
    "        locs, labels = plt.xticks()\n",
    "        plt.tick_params(axis='x', which='major', labelsize=8)\n",
    "        plt.tick_params(axis='y', which='major', labelsize=8)\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f9d2f8541d8a53344730cadb5a2b9752559d17fc"
   },
   "outputs": [],
   "source": [
    "def balanced_cv(conf_mat):\n",
    "    assert len(conf_mat.shape) == 2\n",
    "    rows, columns = conf_mat.shape\n",
    "    intra_class_scores = np.zeros((1, columns))\n",
    "    column_sums = np.sum(conf_mat, axis=0)\n",
    "    for c in range(columns):\n",
    "        intra_class_scores[0][c] = float(conf_mat[c][c])/column_sums[c]\n",
    "        \n",
    "    balanced_score = np.mean(intra_class_scores)\n",
    "    return balanced_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('X_train.csv')\n",
    "sampl = pd.read_csv('sample_submission.csv')\n",
    "test = pd.read_csv('X_test.csv')\n",
    "target = pd.read_csv('y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bfc230e8283491c2cfe124b6c5c2a08f7560a14a"
   },
   "outputs": [],
   "source": [
    "totalt = data.isnull().sum().sort_values(ascending=False)\n",
    "percent = (data.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([totalt, percent], axis=1, keys=['Total', 'Percent'])\n",
    "# missing_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a4bdd12a7223d80e2d4c6c9be217935a5b80d526"
   },
   "outputs": [],
   "source": [
    "totalt = test.isnull().sum().sort_values(ascending=False)\n",
    "percent = (test.isnull().sum()/data.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([totalt, percent], axis=1, keys=['Total', 'Percent'])\n",
    "# missing_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "397df9d46c66cd5eab36b171661b603c3b4ab4fe"
   },
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid')\n",
    "sns.countplot(y = 'surface',\n",
    "              data = target,\n",
    "              order = target['surface'].value_counts().index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "20d703b6ce001c09a776a31a3a95c01c65b3ed1d"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "839cfc267c2ca5a8aab619cfd7e265da8c5f3388"
   },
   "outputs": [],
   "source": [
    "def feat_eng(data):\n",
    "    df = pd.DataFrame()\n",
    "    data['totl_anglr_vel'] = (data['angular_velocity_X']**2 + data['angular_velocity_Y']**2 +\n",
    "                             data['angular_velocity_Z'])** 0.5\n",
    "    data['totl_linr_acc'] = (data['linear_acceleration_X']**2 + data['linear_acceleration_Y']**2 +\n",
    "                             data['linear_acceleration_Z'])**0.5\n",
    "    data['totl_xyz'] = (data['orientation_X']**2 + data['orientation_Y']**2 +\n",
    "                            data['orientation_Z'])**0.5\n",
    "    #Lets derive one more column since there is a relationship in velocity and acceleration\n",
    "    # v = u + a*t , u is initial velocty. if u = 0, then v = at means t = v/a\n",
    "    # but value of acceleration is more and value of velocity is less, lets do a/v relation\n",
    "    data['acc_vs_vel'] = data['totl_linr_acc'] / data['totl_anglr_vel']\n",
    "    \n",
    "    # Deriving more feature, since we are reducing rows now, we should know min,max,mean values\n",
    "    for col in data.columns:\n",
    "        if col in ['row_id','series_id','measurement_number']:\n",
    "            continue\n",
    "        df[col + '_mean'] = data.groupby(['series_id'])[col].mean()\n",
    "        df[col + '_max'] = data.groupby(['series_id'])[col].max()\n",
    "        df[col + '_min'] = data.groupby(['series_id'])[col].min()\n",
    "        df[col + '_std'] = data.groupby(['series_id'])[col].std()\n",
    "        # df[col + '_maxtoMin'] = df[col + '_max'] / df[col + '_min']\n",
    "        df[col + '_mean_abs_chg'] = data.groupby(['series_id'])[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n",
    "        df[col + '_abs_min'] = data.groupby(['series_id'])[col].apply(lambda x: np.min(np.abs(x)))\n",
    "        df[col + '_abs_max'] = data.groupby(['series_id'])[col].apply(lambda x: np.max(np.abs(x)))\n",
    "        df[col + '_abs_avg'] = (df[col + '_abs_min'] + df[col + '_abs_max'])/2\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da872f84dbe19df5250f319ec34750279798b4bf"
   },
   "outputs": [],
   "source": [
    "data = feat_eng(data)\n",
    "test = feat_eng(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.columns.values[0:10]\n",
    "plot_feature_distribution(data, test, 'train', 'test', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "35b15c545c9bea8e3e023d32ea3112ef7bbe016f"
   },
   "outputs": [],
   "source": [
    "data.head()\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d860de8e308eb3f290ec8b117138a29b7297c67a"
   },
   "outputs": [],
   "source": [
    "# Filling missing data by zeroes\n",
    "data.fillna(0,inplace=True)\n",
    "data.replace(-np.inf,0,inplace=True)\n",
    "data.replace(np.inf,0,inplace=True)\n",
    "test.fillna(0,inplace=True)\n",
    "test.replace(-np.inf,0,inplace=True)\n",
    "test.replace(np.inf,0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "47a5ac7c0189bd91b8ddda57557f18e78ef0cd9c"
   },
   "outputs": [],
   "source": [
    "#Label Encoding\n",
    "target['surface'] = le.fit_transform(target['surface'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffc836028e31ba704b301305afc08fc4166e8dee"
   },
   "outputs": [],
   "source": [
    "split_count = 5\n",
    "folds = StratifiedKFold(n_splits=split_count, shuffle=True, random_state=1337)\n",
    "# folds = GroupShuffleSplit(n_splits=split_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1bde524f57f7e5b8c6250c3178147445adb6682e"
   },
   "outputs": [],
   "source": [
    "predicted = np.zeros((test.shape[0],9))\n",
    "# measured= np.zeros((data.shape[0]))\n",
    "score = 0\n",
    "balanced_cv_sum = 0\n",
    "# Balanced model training gives slightly worse results on pubLB.\n",
    "model = RandomForestClassifier(n_estimators=200, random_state=1337)\n",
    "# model = XGBClassifier(tree_method='gpu_hist')\n",
    "# model = LGBMClassifier(device='gpu')\n",
    "for times, (trn_idx, val_idx) in enumerate(folds.split(data.values,target['surface'].values)):\n",
    "    model.fit(data.iloc[trn_idx],target['surface'][trn_idx])\n",
    "    # measured[val_idx] = model.predict(data.iloc[val_idx])\n",
    "    # predicted += model.predict_proba(test)/folds.n_splits\n",
    "    score += model.score(data.iloc[val_idx],target['surface'][val_idx])\n",
    "    print(\"Fold: {} score: {}\".format(times,model.score(data.iloc[val_idx],target['surface'][val_idx])))\n",
    "    cm = confusion_matrix(model.predict(data.iloc[val_idx]), target['surface'].iloc[val_idx])\n",
    "    '''\n",
    "    plt.figure()\n",
    "    sns.heatmap(cm, annot=True, cmap=\"YlOrBr\")\n",
    "    '''\n",
    "    balscore = balanced_cv(cm)\n",
    "    print('balanced cv score', balscore)\n",
    "    balanced_cv_sum +=balscore\n",
    "    gc.collect()\n",
    "print('Avg Accuracy', score / folds.n_splits)\n",
    "print('Avg Balanced Accuracy', balanced_cv_sum / folds.n_splits)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7b987ad134006f8e162eacac0ca4aaab64c88df"
   },
   "outputs": [],
   "source": [
    "model.fit(data, target['surface'])\n",
    "predicted = model.predict_proba(test)\n",
    "sampl['surface'] = le.inverse_transform(predicted.argmax(axis=1))\n",
    "sampl.to_csv('submission.csv', index=False)\n",
    "# sampl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
