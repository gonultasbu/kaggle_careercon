{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from seaborn import countplot,lineplot, barplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import autokeras as ak\n",
    "\n",
    "\n",
    "def quaternion_to_euler(x, y, z, w):\n",
    "    import math\n",
    "    t0 = +2.0 * (w * x + y * z)\n",
    "    t1 = +1.0 - 2.0 * (x * x + y * y)\n",
    "    X = math.atan2(t0, t1)\n",
    "\n",
    "    t2 = +2.0 * (w * y - z * x)\n",
    "    t2 = +1.0 if t2 > +1.0 else t2\n",
    "    t2 = -1.0 if t2 < -1.0 else t2\n",
    "    Y = math.asin(t2)\n",
    "\n",
    "    t3 = +2.0 * (w * z + x * y)\n",
    "    t4 = +1.0 - 2.0 * (y * y + z * z)\n",
    "    Z = math.atan2(t3, t4)\n",
    "\n",
    "    return X, Y, Z\n",
    "\n",
    "def fe(actual):\n",
    "    new = pd.DataFrame()\n",
    "    actual['total_angular_velocity'] = actual['angular_velocity_X'] + actual['angular_velocity_Y'] + actual['angular_velocity_Z']\n",
    "    actual['total_linear_acceleration'] = actual['linear_acceleration_X'] + actual['linear_acceleration_Y'] + actual['linear_acceleration_Z']\n",
    "    \n",
    "    actual['acc_vs_vel'] = actual['total_linear_acceleration'] / actual['total_angular_velocity']\n",
    "    \n",
    "    x, y, z, w = actual['orientation_X'].tolist(), actual['orientation_Y'].tolist(), actual['orientation_Z'].tolist(), actual['orientation_W'].tolist()\n",
    "    nx, ny, nz = [], [], []\n",
    "    for i in range(len(x)):\n",
    "        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n",
    "        nx.append(xx)\n",
    "        ny.append(yy)\n",
    "        nz.append(zz)\n",
    "    \n",
    "    actual['euler_x'] = nx\n",
    "    actual['euler_y'] = ny\n",
    "    actual['euler_z'] = nz\n",
    "    \n",
    "    def f1(x):\n",
    "        return np.mean(np.diff(np.abs(np.diff(x))))\n",
    "    \n",
    "    def f2(x):\n",
    "        return np.mean(np.abs(np.diff(x)))\n",
    "    \n",
    "    for col in actual.columns:\n",
    "        if col in ['row_id', 'series_id', 'measurement_number']:\n",
    "            continue\n",
    "        new[col + '_mean'] = actual.groupby(['series_id'])[col].mean()\n",
    "        new[col + '_min'] = actual.groupby(['series_id'])[col].min()\n",
    "        new[col + '_max'] = actual.groupby(['series_id'])[col].max()\n",
    "        new[col + '_std'] = actual.groupby(['series_id'])[col].std()\n",
    "        new[col + '_max_to_min'] = new[col + '_max'] / new[col + '_min']\n",
    "        \n",
    "        # Change. 1st order.\n",
    "        new[col + '_mean_abs_change'] = actual.groupby('series_id')[col].apply(f2)\n",
    "        \n",
    "        # Change of Change. 2nd order.\n",
    "        new[col + '_mean_change_of_abs_change'] = actual.groupby('series_id')[col].apply(f1)\n",
    "        \n",
    "        new[col + '_abs_max'] = actual.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n",
    "        new[col + '_abs_min'] = actual.groupby('series_id')[col].apply(lambda x: np.min(np.abs(x)))\n",
    "\n",
    "    return new\n",
    "\n",
    "\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "SS = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train['surface'] = le.fit_transform(y_train['surface'])\n",
    "\n",
    "X_train = fe(X_train)\n",
    "X_test = fe(X_test)\n",
    "\n",
    "# Imputation   \n",
    "X_train.fillna(0, inplace = True)\n",
    "X_test.fillna(0, inplace = True)\n",
    "\n",
    "X_train.replace(-np.inf, 0, inplace = True)\n",
    "X_train.replace(np.inf, 0, inplace = True)\n",
    "X_test.replace(-np.inf, 0, inplace = True)\n",
    "X_test.replace(np.inf, 0, inplace = True)\n",
    "# SS.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________ 0 ____________________\n",
      "train_score  0.8776119402985074\n",
      "cv_score  0.4880503144654088\n",
      "____________________ 1 ____________________\n",
      "train_score  0.8590006844626967\n",
      "cv_score  0.46621621621621623\n",
      "____________________ 2 ____________________\n",
      "train_score  0.8590280012874155\n",
      "cv_score  0.5419630156472262\n",
      "____________________ 3 ____________________\n",
      "train_score  0.8866045615162222\n",
      "cv_score  0.44619799139167865\n",
      "____________________ 4 ____________________\n",
      "train_score  0.863852961198094\n",
      "cv_score  0.5080275229357798\n",
      "________________________________________\n",
      "Avg Accuracy 0.49009101213126194\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold, GroupShuffleSplit\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "folds = GroupShuffleSplit(n_splits=5)\n",
    "sub_preds = np.zeros((X_test.shape[0], 9))\n",
    "score_sum = 0\n",
    "# clf = LGBMClassifier(device='gpu')\n",
    "clf = XGBClassifier(gamma = 10) \n",
    "# clf = RandomForestClassifier(n_estimators = 200, n_jobs = -1)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(folds.split(X_train, y_train['surface'],\n",
    "                                                groups=y_train['group_id'])):\n",
    "\n",
    "    print('_'*20, i, '_'*20)\n",
    "    clf.fit(X_train.iloc[train_index], y_train['surface'][train_index])\n",
    "    score_sum += clf.score(X_train.iloc[test_index], y_train['surface'][test_index])\n",
    "    print('train_score ', clf.score(X_train.iloc[train_index], y_train['surface'][train_index]))\n",
    "    print('cv_score ', clf.score(X_train.iloc[test_index], y_train['surface'][test_index]))\n",
    "    \n",
    "print('_'*40)\n",
    "print('Avg Accuracy', score_sum / folds.n_splits)\n",
    "clf.fit(X_train, y_train['surface'])\n",
    "sub_preds = clf.predict_proba(X_test)\n",
    "SS['surface'] = le.inverse_transform(sub_preds.argmax(axis=1))\n",
    "SS.to_csv('rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5-fold scores\n",
    "clf = RandomForestClassifier(n_estimators = 200, n_jobs = -1 -> 0.5058142416039874\n",
    "clf = XGBClassifier(tree_method='gpu_hist') -> 0.5060708581905506\n",
    "clf = LGBMClassifier(device='gpu', is_unbalanced='True') -> 0.5042298003024369\n",
    "clf = XGBClassifier(tree_method = \"gpu_hist\", subsample = 0.5) -> 0.5134247735482932\n",
    "clf = XGBClassifier(predictor = 'gpu_predictor', subsample = 0.5, tree_method = 'gpu_hist', reg_lambda='2') -> 0.5168309973381262 0.63 submission\n",
    "'''\n",
    "# The model is definitely overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
